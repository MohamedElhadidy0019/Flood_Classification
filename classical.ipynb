{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as mypre\n",
    "import features_extraction as myfe\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 64, 64, 3) (922,)\n"
     ]
    }
   ],
   "source": [
    "X, y = mypre.read_dataset(pth='./dataset64/')\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghieath\\AppData\\Roaming\\Python\\Python310\\site-packages\\skimage\\_shared\\utils.py:394: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel, or set channel_axis.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    x = mypre.fix_illumination(mypre.fix_contrast(x))\n",
    "print(X.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOG=0\n",
    "LBP=0\n",
    "GLCM=0\n",
    "COLOR_HISTOGRAM=1\n",
    "COLOR_MOMENTS=0\n",
    "COLOR_CORRELOGRAM=0\n",
    "GABOR=0\n",
    "WATERSHED=0\n",
    "CANNY=0\n",
    "SOBEL=0\n",
    "#\n",
    "args = (HOG, LBP, GLCM, COLOR_HISTOGRAM, COLOR_MOMENTS, COLOR_CORRELOGRAM,\n",
    "        GABOR, WATERSHED, CANNY, SOBEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 64)\n"
     ]
    }
   ],
   "source": [
    "X_features = [myfe.extract_features(x, *args) for x in X]\n",
    "X_features = np.array(X_features)\n",
    "print(X_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoooooooooooooooooooooooooooooooooooooooooool up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro f1 import\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Train model\n",
    "def test_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    name = str(model).split('(')[0]\n",
    "    # print(name, f1_score(y_test, y_pred, average='macro').round(3))\n",
    "    f1 = np.round(f1_score(y_test, y_pred, average='macro'), 3) *100\n",
    "    f1 = str(f1)[:4]\n",
    "    print(f1, end=' |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.5 |"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "for clf in [\n",
    "            # SVC(kernel='linear', C=1.0, random_state=42), \n",
    "            # GaussianNB(),\n",
    "            # RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42),\n",
    "            XGBClassifier(\n",
    "                booster='gbtree',\n",
    "                learning_rate=0.3,\n",
    "                max_depth=3,\n",
    "                # objective=\"multi:softprob\",\n",
    "                random_state=42,\n",
    "                # num_class=2,\n",
    "                # eval_metric=\"auc\",\n",
    "                # eval_metric=\"mlogloss\",\n",
    "            ),\n",
    "            # AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            # DecisionTreeClassifier(random_state=42)\n",
    "            ]:\n",
    "    test_model(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Random Search CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Grid Search CV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Create the parameter grid based on the results of random search\n",
    "# XGBClassifier\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.3, 0.5, 0.7, 1],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "    'objective': ['multi:softprob'],\n",
    "    'random_state': [42],\n",
    "    'num_class': [2],\n",
    "    'eval_metric': ['auc', 'mlogloss'],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "model = XGBClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid,\n",
    "                            cv = 3, n_jobs = -1, verbose = 2, scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# # Grid search\n",
    "# grid_search = GridSearchCV(estimator = model, param_grid = param_grid,\n",
    "#                             cv = 3, n_jobs = -1, verbose = 2, scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results (macro F1):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Used | SVM | Naive Bayes | Random Forest | XGBoost | AdaBoost | Decision Tree | MLP\n",
    "--- | --- | --- | --- | --- | --- | --- | --- |\n",
    "hog, lbp, glcm, color_histogram, color_moments | 77.8 | 71.9 | 79.5 | 89.2 | 82.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Used | SVM | XGBoost | AdaBoost\n",
    "--- | --- | --- | ---\n",
    "o\n",
    "**64x64**\n",
    "hog | 71.8 |77.8 |72.8\n",
    "LBP | 32. |69.7 |67.6\n",
    "GLCM | 69.1 |72.9 |71.5\n",
    "Color Histogram | 68.6 |75.6 |74.6\n",
    "Color Moments (lab) | 71.5 |81. |73.9\n",
    "Collerogram | 49.5 |74.0 |73.5 |\n",
    "Gabor Filter | 53.9 |67.5 |61.6 |\n",
    "WaterShed | 32.0 |53.5 |47.9\n",
    "Moments (lab), LBP | 69.9 |81.6 |76.0\n",
    "Moments (lab), hog | 73.5 |82.1 |78.9\n",
    "Moments (lab), GLCM | 75.1 |82.6 |75.0\n",
    "Moments, Hist | 82.1 |**85.9** |82.7\n",
    "Correlogram, gabor, watershed | 63.2 |76.1 |73.3\n",
    "Correlogram, gabor | 63.2 |77.8 |76.7 |\n",
    "o\n",
    "224x224 | ||\n",
    "Hist | 70.7 |78.9 |74.4\n",
    "GLCM | 71.7 |64.8 |67.5\n",
    "Moments | 75.9|82.6 |82.6\n",
    "Moments, Hist | 79.5 |83.2 |81.5\n",
    "hog,lbp,glcm,histo,moments,watershed | 78.9 | 86.5 | TLE\n",
    "hog,lbp,glcm,hist,mom,correl,gab | 78.9 | 87.5 | 87\n",
    "o\n",
    "tuning XGBoost\n",
    "hog,glcm,hist,mom,correl | | 88.6 |\n",
    "hog,glcm,hist,mom | | 82.1 |\n",
    "glcm,hist,mom,correl | | 90.2 |\n",
    "lbp,glcm,hist,mom,correl | |  91.3 |\n",
    "lbp,glcm,hist,mom,correl,gabor | | 90.8 |\n",
    "lbp,hist,mom,correl | | 91.3 |\n",
    "lbp,mom,correl | | 90.3 |\n",
    "lbp,correl | | 89.7 |\n",
    "o\n",
    "a | kernel='rbf', C=50.0, gamma=1.88 | | n_estimators=400\n",
    "lbp,hist,correl | rbf:91.9 | 92.4 | 91.9\n",
    "lbp,glcm,hist,correl | | 92.4 |\n",
    "lbp,hist,mom,correl | | **93** |\n",
    "lbp,glcm,hist,mom,correl |  | **93** | "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Used | SVM | Naive Bayes | Random Forest | XGBoost | AdaBoost | Decision Tree\n",
    "--- | --- | --- | --- | --- | --- | --- |\n",
    "o \n",
    "**64x64**\n",
    "hog | 71.8 |71.3 |75.1 |77.8 |72.8 |66.9 |58.7 | 73.9 |\n",
    "LBP | 32. |55.8 |61.4 |69.7 |67.6 |53. |\n",
    "GLCM | 69.1 |65.9 |68.1 |72.9 |71.5 |68.6 |70.\n",
    "Color Histogram | 68.6 |73.1 |69.7 |75.6 |74.6 |65.4 |73.8\n",
    "Color Moments (lab) | 71.5 |72.8 |70.9 |81. |73.9 |75.6 |\n",
    "WaterShed | 32.0 |54.1 |58.4 |53.5 |47.9 |45.9 |\n",
    "Moments (lab), LBP | 69.9 |73.6 |67.5 |81.6 |76.0 |78.9 |\n",
    "Moments (lab), hog | 73.5 |71.3 |76.7 |82.1 |78.9 |70.7 |\n",
    "Moments (lab), GLCM | 75.1 |73.2 |75.3 |82.6 |75.0 |81.0 |\n",
    "Moments, Hist | 82.1 |73.5 |82.5 |**85.9** |82.7 |76.8 |\n",
    "o\n",
    "224x224 | \n",
    "Hist | 70.7 |70.5 |73.2 |78.9 |74.4 |70.3 |\n",
    "GLCM | 71.7 |70.3 |70.7 |64.8 |67.5 |65.9 |\n",
    "Moments | 75.9| 73.6 |76.6 |82.6 |82.6 | 75.9\n",
    "Moments, Hist | 79.5 ||75.9 |83.2 |81.5 |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
